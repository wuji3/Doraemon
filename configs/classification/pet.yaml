model:
  task: classification
  name: torchvision-swin_t
  image_size: &resize_size 224
  kwargs: {} # kwargs feed into torchvision-style models.__init__ 'attention_dropout': 0.1,
  num_classes: 35
  pretrained: True
  backbone_freeze: False
  bn_freeze: False
  bn_freeze_affine: False
  attention_pool: False
data:
  root: oxford-iiit-pet/pet  # -train -val
  nw: 4 # if not multi-nw, set to 0
  train:
    bs: 32 # one gpus if DDP
    common_aug: null 
    class_aug: null 
      #S: 0 1 2 4 5 6
      #B-: 0 1 2 4 5 6
    augment: # refer to utils/augment.py
       - random_choice:
          transforms: 
            - random_color_jitter:
                brightness: 0.1
                contrast: 0.1
                saturation: 0.1
                hue: 0.1
            - random_cutout:
                n_holes: 3
                length: 12
                prob: 0.1
                color: [0, 255]
            - random_gaussianblur:
                kernel_size: 5
            - random_rotate:
                degrees: 10
            - random_autocontrast:
                p: 0.5
            - random_adjustsharpness:
                p: 0.5
            - random_augmix: 
                severity: 3
       - random_horizonflip: 
           p: 0.5
       - random_choice:
          transforms:
            - resize_and_padding: 
                size: *resize_size
                training: True
            - random_crop_and_resize:
                size: *resize_size
                scale: [0.7, 1]
          p: [0.9, 0.1]
       - to_tensor: no_params
       - normalize: 
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]
    aug_epoch: 20 # augment for epochs, on which epoch to weaken, except warm_epoch
  val:
    bs: 32
    augment:
        - resize_and_padding:
            size: *resize_size
            training: False
        - to_tensor: no_params
        - normalize: 
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]
hyp:
  epochs: 32
  lr0: 0.008 # sgd=1e-2, adam=1e-3
  lrf_ratio: null # decay to lrf_ratio * lr0, if None, 0.1
  momentum: 0.937
  weight_decay: 0.0005
  warmup_momentum: 0.8
  warm_ep: 0
  loss:
    ce: True
    bce:
      - False
      - 0.5
      - True # multi-label
  label_smooth: 0.1
  strategy:
    prog_learn: True
    mixup:
      - 0.1 
      - [0, 20]
    focal: 
      - False
      - 0.25
      - 1.5
    ohem:
      - False
      - 8 # min_kept
      - 0.7 # thresh_prob
      - 255 # ignore_index
  optimizer: 
    - sgd # sgd, adam or sam
    - False # True or False
  scheduler: cosine # linear or cosine