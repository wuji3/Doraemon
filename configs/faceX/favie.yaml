model:
  task: cbir
  backbone:
    # swintransformer: # tiny small base
    #   model_size: base
    #   image_size: 224
    #   in_chans: 3
    #   feat_dim: 128
    convnext: # tiny small base large
      model_size: base
      feat_dim: 128
      image_size: 224
  head:
    arcface:
      feat_dim: 128
      num_class: 4820
      margin_arc: 0.35
      margin_am: 0.0
      scale: 32
data:
  root: /home/duke/visiondk/data/favie/v3-embedding  # -train -val
  nw: 64 # if not multi-nw, set to 0
  train:
    bs: 160 # one gpus if DDP
    common_aug: null 
    class_aug: null
      #S: 0 1 2 4 5 6
      #B-: 0 1 2 4 5 6
    augment: # refer to utils/augment.py
       - random_choice:
          transforms: 
            - random_color_jitter:
                brightness: 0.1
                contrast: 0.1
                saturation: 0.1
                hue: 0.1
            - random_cutout:
                n_holes: 3
                length: 12
                prob: 0.1
                color: [0, 255]
            - random_gaussianblur:
                kernel_size: 5
            - random_rotate:
                degrees: 20
            - random_autocontrast:
                p: 0.5
            - random_adjustsharpness:
                p: 0.5
            - random_augmix: 
                severity: 3
       - random_horizonflip: 
           p: 0.5
       - random_choice:
          transforms:
            - resize_and_padding: 
                size: 224
            - random_crop_and_resize:
                size: 224
                scale: [0.7, 1]
       - to_tensor: no_params
    aug_epoch: 90 # augment for epochs, on which epoch to weaken, except warm_epoch
  val:
    bs: 128
    metrics:
      metrics: [mrr, recall, precision, auc, ndcg]
      cutoffs: [1, 3, 5] 
    augment:
        - resize_and_padding:
            size: 224
        - to_tensor: no_params
hyp:
  epochs: 100
  lr0: 0.01 # sgd=1e-2, adam=1e-3
  lrf_ratio: null # decay to lrf_ratio * lr0, if None, 0.1
  momentum: 0.937
  weight_decay: 0.0005
  warmup_momentum: 0.8
  warm_ep: 1
  loss:
    ce: True
  label_smooth: 0.0
  optimizer: 
    - sgd # sgd, adam or sam
    - True # Different layers in the model set different learning rates, in built/layer_optimizer
  scheduler: cosine_with_warm # linear or cosine
